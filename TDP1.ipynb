{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMHmU8qXg1FePdV6mVTi1bl"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ac_ZBzXibf-",
        "outputId": "9411b833-f379-42e7-ce87-1dff520abf92"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "TensorFlow version: 2.19.0\n",
            "Goodbye world\n"
          ]
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# === STEP 2: LOAD THE DATASET ===\n",
        "# We'll use Fashion MNIST, a classic dataset of 28x28 grayscale images of clothing.\n",
        "# Keras has it built-in, so loading is one line of code.\n",
        "fashion_mnist = keras.datasets.fashion_mnist\n",
        "(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n",
        "\n",
        "# The images are arrays of pixels (0-255). We normalize them to be between 0 and 1.\n",
        "# This helps the network train better.\n",
        "train_images = train_images / 255.0\n",
        "test_images = test_images / 255.0\n",
        "\n",
        "# === STEP 3: BUILD THE NEURAL NETWORK MODEL ===\n",
        "# We use the 'Sequential' API, which is like a list where you add layers one by one.\n",
        "model = keras.Sequential([\n",
        "    # This layer flattens the 2D image (28x28) into a 1D array (784 elements).\n",
        "    keras.layers.Flatten(input_shape=(28, 28)),\n",
        "\n",
        "    # This is a \"Dense\" or \"fully-connected\" layer. It has 128 neurons.\n",
        "    # 'relu' is a common activation function.\n",
        "    keras.layers.Dense(128, activation='relu'),\n",
        "\n",
        "    # This is the output layer. It has 10 neurons, one for each clothing class.\n",
        "    # 'softmax' activation converts the output into probabilities for each class.\n",
        "    keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "# === STEP 4: COMPILE THE MODEL ===\n",
        "# Before training, we configure the learning process.\n",
        "model.compile(optimizer='adam',  # 'adam' is an efficient, popular optimizer.\n",
        "              loss='sparse_categorical_crossentropy', # This is the loss function for classification problems.\n",
        "              metrics=['accuracy']) # We want to track the 'accuracy' metric during training.\n",
        "\n",
        "# Print a summary of the model you just built\n",
        "model.summary()\n",
        "\n",
        "# === STEP 5: TRAIN THE MODEL ===\n",
        "# We call 'fit()' to start the training.\n",
        "# - We pass in our training data and labels.\n",
        "# - 'epochs=10' means the model will see the entire dataset 10 times.\n",
        "# - 'validation_split=0.2' saves 20% of the training data to validate the model's performance after each epoch.\n",
        "history = model.fit(train_images, train_labels, epochs=10, validation_split=0.2)\n",
        "\n",
        "# === STEP 6: EVALUATE AND VISUALIZE RESULTS ===\n",
        "# Now, we check the model's performance on the test data it has never seen before.\n",
        "print(\"\\n--- Evaluating model on test data ---\")\n",
        "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
        "print('\\nTest accuracy:', test_acc)\n",
        "\n",
        "# The 'history' object contains the data from training. We can use it to plot graphs.\n",
        "history_dict = history.history\n",
        "acc = history_dict['accuracy']\n",
        "val_acc = history_dict['val_accuracy']\n",
        "loss = history_dict['loss']\n",
        "val_loss = history_dict['val_loss']\n",
        "epochs_range = range(1, len(acc) + 1)\n",
        "\n",
        "# Plotting the accuracy and loss\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(epochs_range, acc, 'bo', label='Training Accuracy')\n",
        "plt.plot(epochs_range, val_acc, 'b', label='Validation Accuracy')\n",
        "plt.title('Training and Validation Accuracy')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.legend()\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(epochs_range, loss, 'bo', label='Training Loss')\n",
        "plt.plot(epochs_range, val_loss, 'b', label='Validation Loss')\n",
        "plt.title('Training and Validation Loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "\n",
        "plt.show()\n",
        "\n",
        "# === STEP 7: SAVE THE MODEL ===\n",
        "# You can save your trained model to a single file.\n",
        "model.save('my_clothing_classifier_model.h5')\n",
        "print(\"\\nModel saved to my_clothing_classifier_model.h5\")\n",
        "\n",
        "# You could load it back later with:\n",
        "# loaded_model = keras.models.load_model('my_clothing_classifier_model.h5')"
      ]
    }
  ]
}